{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3789fb",
   "metadata": {},
   "source": [
    "# Static IDS Failure: Concept Drift & Catastrophic Forgetting\n",
    "\n",
    "**Experiment**: Ch·ª©ng minh s·ª± th·∫•t b·∫°i c·ªßa Static IDS khi g·∫∑p distribution shifts v√† rare attacks trong NSL-KDD test set.\n",
    "\n",
    "---\n",
    "\n",
    "## C·∫•u tr√∫c Notebook:\n",
    "\n",
    "### **PH·∫¶N C∆† B·∫¢N**: Overall Evaluation\n",
    "- Train on **FULL TRAIN SET** (125,973 samples - Old Data 2015)\n",
    "- Test on **FULL TEST SET** (22,544 samples - New Data 2016)\n",
    "- ƒêo accuracy drop, F1-score, confusion matrix\n",
    "- Ph√¢n t√≠ch per-class performance\n",
    "\n",
    "### **PH·∫¶N N√ÇNG CAO**: Period-Based Evaluation\n",
    "- Chia test set th√†nh 5 periods (DoS, Probe, R2L, U2R, Mixed)\n",
    "- T√≠nh **Forgetting Measure (FM)** cho t·ª´ng period\n",
    "- Visualization chi ti·∫øt: Performance degradation over periods\n",
    "- Analysis: Catastrophic forgetting patterns\n",
    "\n",
    "---\n",
    "\n",
    "## Key Hypotheses:\n",
    "1. ‚úÖ Model fits well on train (DoS-heavy, R2L/U2R rare)\n",
    "2. ‚ùå Model FAILS on test (R2L surge +16x, U2R +7.5x)\n",
    "3. üìâ **Catastrophic Forgetting**: FM cao cho rare classes\n",
    "4. üéØ **Need Adaptive Learning**: Static model kh√¥ng ph√π h·ª£p cho IDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccfd9b5",
   "metadata": {},
   "source": [
    "## 1. Setup & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165413f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully!\n",
      "Random seed: 42\n",
      "NumPy: 2.4.2 | Pandas: 3.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score,\n",
    "                             confusion_matrix, classification_report)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n",
    "print(f\"NumPy: {np.__version__} | Pandas: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96cc405",
   "metadata": {},
   "source": [
    "## 2. Load NSL-KDD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69295945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dataset loaded successfully!\n",
      "\n",
      "üì¶ Train Set (Old Data - 2015):\n",
      "   Shape: (125973, 43) (125,973 samples, 43 features)\n",
      "\n",
      "üì¶ Test Set (New Data - 2016):\n",
      "   Shape: (22544, 43) (22,544 samples, 43 features)\n",
      "\n",
      "First 3 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_shells</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <th>is_host_login</th>\n",
       "      <th>is_guest_login</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neptune</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  num_failed_logins  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0               0       0    0                  0   \n",
       "1         0           udp     other   SF        146          0     0               0       0    0                  0   \n",
       "2         0           tcp   private   S0          0          0     0               0       0    0                  0   \n",
       "\n",
       "   logged_in  num_compromised  root_shell  su_attempted  num_root  num_file_creations  num_shells  num_access_files  \\\n",
       "0          0                0           0             0         0                   0           0                 0   \n",
       "1          0                0           0             0         0                   0           0                 0   \n",
       "2          0                0           0             0         0                   0           0                 0   \n",
       "\n",
       "   num_outbound_cmds  is_host_login  is_guest_login  count  srv_count  serror_rate  srv_serror_rate  rerror_rate  \\\n",
       "0                  0              0               0      2          2          0.0              0.0          0.0   \n",
       "1                  0              0               0     13          1          0.0              0.0          0.0   \n",
       "2                  0              0               0    123          6          1.0              1.0          0.0   \n",
       "\n",
       "   srv_rerror_rate  same_srv_rate  diff_srv_rate  srv_diff_host_rate  dst_host_count  dst_host_srv_count  \\\n",
       "0              0.0           1.00           0.00                 0.0             150                  25   \n",
       "1              0.0           0.08           0.15                 0.0             255                   1   \n",
       "2              0.0           0.05           0.07                 0.0             255                  26   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                    0.17                    0.03                         0.17                          0.0   \n",
       "1                    0.00                    0.60                         0.88                          0.0   \n",
       "2                    0.10                    0.05                         0.00                          0.0   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate    label  difficulty  \n",
       "0                   0.0                       0.0                  0.05                       0.0   normal          20  \n",
       "1                   0.0                       0.0                  0.00                       0.0   normal          15  \n",
       "2                   1.0                       1.0                  0.00                       0.0  neptune          19  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define column names for NSL-KDD\n",
    "col_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n",
    "    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n",
    "    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n",
    "    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\",\n",
    "    \"label\", \"difficulty\"\n",
    "]\n",
    "\n",
    "# Load datasets\n",
    "train_path = \"data/KDDTrain+.txt\"\n",
    "test_path = \"data/KDDTest+.txt\"\n",
    "\n",
    "df_train = pd.read_csv(train_path, names=col_names, header=None)\n",
    "df_test = pd.read_csv(test_path, names=col_names, header=None)\n",
    "\n",
    "print(f\"‚úì Dataset loaded successfully!\")\n",
    "print(f\"\\nüì¶ Train Set (Old Data - 2015):\")\n",
    "print(f\"   Shape: {df_train.shape} ({df_train.shape[0]:,} samples, {df_train.shape[1]} features)\")\n",
    "print(f\"\\nüì¶ Test Set (New Data - 2016):\")\n",
    "print(f\"   Shape: {df_test.shape} ({df_test.shape[0]:,} samples, {df_test.shape[1]} features)\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364214b",
   "metadata": {},
   "source": [
    "## 3. Label Mapping & Preprocessing\n",
    "\n",
    "Map c√°c attack labels c·ª• th·ªÉ th√†nh 5 categories ch√≠nh:\n",
    "- **Normal**: normal\n",
    "- **DoS**: apache2, back, land, neptune, mailbomb, pod, processtable, smurf, teardrop, udpstorm, worm\n",
    "- **Probe**: ipsweep, mscan, nmap, portsweep, saint, satan\n",
    "- **R2L**: ftp_write, guess_passwd, imap, multihop, named, phf, sendmail, snmpgetattack, snmpguess, spy, warezclient, warezmaster, xlock, xsnoop\n",
    "- **U2R**: buffer_overflow, loadmodule, perl, ps, rootkit, sqlattack, xterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef998a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train set...\n",
      "Processing test set...\n",
      "\n",
      "‚úì Preprocessing completed!\n",
      "\n",
      "üìä Train Set - Category Distribution:\n",
      "   Normal: 67,343 (53.46%)\n",
      "   DoS: 45,927 (36.46%)\n",
      "   Probe: 11,656 (9.25%)\n",
      "   R2L: 995 (0.79%)\n",
      "   U2R: 52 (0.04%)\n",
      "\n",
      "üìä Test Set - Category Distribution:\n",
      "   Normal: 9,711 (43.08%)\n",
      "   DoS: 7,460 (33.09%)\n",
      "   R2L: 2,885 (12.80%)\n",
      "   Probe: 2,421 (10.74%)\n",
      "   U2R: 67 (0.30%)\n"
     ]
    }
   ],
   "source": [
    "def get_attack_category(label: str) -> str:\n",
    "    \"\"\"Map attack labels to 5 main categories\"\"\"\n",
    "    label = label.lower().strip()\n",
    "    \n",
    "    if 'normal' in label:\n",
    "        return 'Normal'\n",
    "    \n",
    "    # DoS attacks\n",
    "    dos_attacks = {'neptune', 'smurf', 'back', 'teardrop', 'pod', 'land',\n",
    "                   'mailbomb', 'processtable', 'udpstorm', 'apache2', 'worm'}\n",
    "    if label in dos_attacks:\n",
    "        return 'DoS'\n",
    "    \n",
    "    # Probe attacks\n",
    "    probe_attacks = {'satan', 'ipsweep', 'nmap', 'portsweep', 'mscan', 'saint'}\n",
    "    if label in probe_attacks:\n",
    "        return 'Probe'\n",
    "    \n",
    "    # R2L attacks\n",
    "    r2l_attacks = {'guess_passwd', 'ftp_write', 'imap', 'phf', 'multihop',\n",
    "                   'warezmaster', 'warezclient', 'spy', 'xlock', 'xsnoop',\n",
    "                   'snmpguess', 'snmpgetattack', 'httptunnel', 'sendmail', 'named'}\n",
    "    if label in r2l_attacks:\n",
    "        return 'R2L'\n",
    "    \n",
    "    # U2R attacks\n",
    "    u2r_attacks = {'buffer_overflow', 'loadmodule', 'rootkit', 'perl',\n",
    "                   'sqlattack', 'xterm', 'ps'}\n",
    "    if label in u2r_attacks:\n",
    "        return 'U2R'\n",
    "    \n",
    "    return 'DoS'  # Fallback\n",
    "\n",
    "def category_to_label(category: str) -> int:\n",
    "    \"\"\"Convert category to numeric label (0-4)\"\"\"\n",
    "    mapping = {'Normal': 0, 'DoS': 1, 'Probe': 2, 'R2L': 3, 'U2R': 4}\n",
    "    return mapping.get(category, 1)\n",
    "\n",
    "def preprocess_nsl_kdd(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess NSL-KDD dataset:\n",
    "    1. Map labels to 5 categories\n",
    "    2. Encode categorical features\n",
    "    3. Drop unnecessary columns\n",
    "    4. Convert to numeric and handle missing values\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create category labels\n",
    "    df[\"label\"] = df[\"label\"].astype(str).str.lower()\n",
    "    df[\"category\"] = df[\"label\"].apply(get_attack_category)\n",
    "    df[\"label_numeric\"] = df[\"category\"].apply(category_to_label).astype(int)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    categorical_cols = [\"protocol_type\", \"service\", \"flag\"]\n",
    "    for col in categorical_cols:\n",
    "        df[col] = pd.factorize(df[col].astype(str))[0]\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(columns=[\"difficulty\", \"label\"], errors='ignore')\n",
    "    \n",
    "    # Convert all to numeric (except category)\n",
    "    for col in df.columns:\n",
    "        if col not in [\"category\", \"label_numeric\"]:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    \n",
    "    df = df.fillna(0.0)\n",
    "    return df\n",
    "\n",
    "# Preprocess datasets\n",
    "print(\"Processing train set...\")\n",
    "df_train_proc = preprocess_nsl_kdd(df_train)\n",
    "print(\"Processing test set...\")\n",
    "df_test_proc = preprocess_nsl_kdd(df_test)\n",
    "\n",
    "print(\"\\n‚úì Preprocessing completed!\")\n",
    "print(f\"\\nüìä Train Set - Category Distribution:\")\n",
    "train_dist = df_train_proc['category'].value_counts()\n",
    "for cat, count in train_dist.items():\n",
    "    pct = count / len(df_train_proc) * 100\n",
    "    print(f\"   {cat}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\nüìä Test Set - Category Distribution:\")\n",
    "test_dist = df_test_proc['category'].value_counts()\n",
    "for cat, count in test_dist.items():\n",
    "    pct = count / len(df_test_proc) * 100\n",
    "    print(f\"   {cat}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304b132",
   "metadata": {},
   "source": [
    "## 4. Extract Features & Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c0bbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Features extracted successfully!\n",
      "\n",
      "üì¶ TRAIN SET:\n",
      "   X_train shape: (125973, 41) (125,973 samples, 41 features)\n",
      "   y_train distribution: {'Normal': np.int64(67343), 'DoS': np.int64(45927), 'Probe': np.int64(11656), 'R2L': np.int64(995), 'U2R': np.int64(52)}\n",
      "\n",
      "üì¶ TEST SET:\n",
      "   X_test shape: (22544, 41) (22,544 samples, 41 features)\n",
      "   y_test distribution: {'Normal': np.int64(9711), 'DoS': np.int64(7460), 'Probe': np.int64(2421), 'R2L': np.int64(2885), 'U2R': np.int64(67)}\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels\n",
    "feature_cols = [c for c in df_train_proc.columns if c not in [\"category\", \"label_numeric\"]]\n",
    "\n",
    "# TRAIN SET\n",
    "X_train = df_train_proc[feature_cols].values.astype(np.float32)\n",
    "y_train = df_train_proc[\"label_numeric\"].values.astype(int)\n",
    "\n",
    "# TEST SET\n",
    "X_test = df_test_proc[feature_cols].values.astype(np.float32)\n",
    "y_test = df_test_proc[\"label_numeric\"].values.astype(int)\n",
    "\n",
    "# Class names\n",
    "class_names = ['Normal', 'DoS', 'Probe', 'R2L', 'U2R']\n",
    "\n",
    "print(\"‚úì Features extracted successfully!\")\n",
    "print(f\"\\nüì¶ TRAIN SET:\")\n",
    "print(f\"   X_train shape: {X_train.shape} ({X_train.shape[0]:,} samples, {X_train.shape[1]} features)\")\n",
    "print(f\"   y_train distribution: {dict(zip(class_names, np.bincount(y_train)))}\")\n",
    "\n",
    "print(f\"\\nüì¶ TEST SET:\")\n",
    "print(f\"   X_test shape: {X_test.shape} ({X_test.shape[0]:,} samples, {X_test.shape[1]} features)\")\n",
    "print(f\"   y_test distribution: {dict(zip(class_names, np.bincount(y_test)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e9843",
   "metadata": {},
   "source": [
    "---\n",
    "# PH·∫¶N C∆† B·∫¢N: Overall Evaluation\n",
    "\n",
    "Train Static Random Forest on **FULL TRAIN SET** ‚Üí Test on **FULL TEST SET**\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Train Static Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51eaa6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING STATIC RANDOM FOREST ON FULL TRAIN SET\n",
      "================================================================================\n",
      "\n",
      "Model configuration:\n",
      "  - n_estimators: 100\n",
      "  - max_depth: 20\n",
      "  - random_state: 42\n",
      "\n",
      "Training on 125,973 samples...\n",
      "‚úì Training completed in 1.22 seconds (0.02 minutes)\n",
      "\n",
      "üìä Performance on TRAIN SET (sanity check):\n",
      "  - Accuracy:        0.9994 (99.94%)\n",
      "  - F1-Score (macro):    0.9582\n",
      "  - F1-Score (weighted): 0.9994\n",
      "\n",
      "‚úÖ Model fits well on historical data (2015)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRAINING STATIC RANDOM FOREST ON FULL TRAIN SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "static_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\nModel configuration:\")\n",
    "print(f\"  - n_estimators: {static_model.n_estimators}\")\n",
    "print(f\"  - max_depth: {static_model.max_depth}\")\n",
    "print(f\"  - random_state: {RANDOM_SEED}\")\n",
    "\n",
    "# Train model\n",
    "import time\n",
    "print(f\"\\nTraining on {len(X_train):,} samples...\")\n",
    "start_time = time.time()\n",
    "static_model.fit(X_train, y_train)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úì Training completed in {train_time:.2f} seconds ({train_time/60:.2f} minutes)\")\n",
    "\n",
    "# Evaluate on train set (sanity check)\n",
    "y_train_pred = static_model.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_f1_macro = f1_score(y_train, y_train_pred, average='macro', zero_division=0)\n",
    "train_f1_weighted = f1_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nüìä Performance on TRAIN SET (sanity check):\")\n",
    "print(f\"  - Accuracy:        {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"  - F1-Score (macro):    {train_f1_macro:.4f}\")\n",
    "print(f\"  - F1-Score (weighted): {train_f1_weighted:.4f}\")\n",
    "print(f\"\\n‚úÖ Model fits well on historical data (2015)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5bbb0c",
   "metadata": {},
   "source": [
    "## 6. Evaluate on TEST SET (New Data with Drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce02300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUATING ON TEST SET (New Data - 2016)\n",
      "================================================================================\n",
      "\n",
      "Predicting on 22,544 test samples...\n",
      "\n",
      "üìä Performance on TEST SET:\n",
      "  - Accuracy:        0.6949 (69.49%)\n",
      "  - F1-Score (macro):    0.4372\n",
      "  - F1-Score (weighted): 0.6466\n",
      "\n",
      "üìâ CATASTROPHIC FORGETTING DETECTED:\n",
      "  - Train Accuracy: 0.9994 (99.94%)\n",
      "  - Test Accuracy:  0.6949 (69.49%)\n",
      "  - Accuracy Drop:  0.3045 (30.47%)\n",
      "\n",
      "‚ùå Model FAILS on evolved threats due to distribution shift!\n",
      "\n",
      "üìã Summary Table:\n",
      "     Dataset  Accuracy  F1-Macro  F1-Weighted Samples\n",
      "Train (2015)    0.9994    0.9582       0.9994 125,973\n",
      " Test (2016)    0.6949    0.4372       0.6466  22,544\n",
      "        Drop    0.3045    0.5210       0.3528       -\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EVALUATING ON TEST SET (New Data - 2016)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Predict on test set\n",
    "print(f\"\\nPredicting on {len(X_test):,} test samples...\")\n",
    "y_test_pred = static_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_f1_macro = f1_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "test_f1_weighted = f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Calculate accuracy drop\n",
    "acc_drop = train_acc - test_acc\n",
    "acc_drop_pct = (acc_drop / train_acc) * 100\n",
    "\n",
    "print(f\"\\nüìä Performance on TEST SET:\")\n",
    "print(f\"  - Accuracy:        {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"  - F1-Score (macro):    {test_f1_macro:.4f}\")\n",
    "print(f\"  - F1-Score (weighted): {test_f1_weighted:.4f}\")\n",
    "\n",
    "print(f\"\\nüìâ CATASTROPHIC FORGETTING DETECTED:\")\n",
    "print(f\"  - Train Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"  - Test Accuracy:  {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"  - Accuracy Drop:  {acc_drop:.4f} ({acc_drop_pct:.2f}%)\")\n",
    "print(f\"\\n‚ùå Model FAILS on evolved threats due to distribution shift!\")\n",
    "\n",
    "# Store results\n",
    "results_summary = pd.DataFrame({\n",
    "    'Dataset': ['Train (2015)', 'Test (2016)', 'Drop'],\n",
    "    'Accuracy': [train_acc, test_acc, acc_drop],\n",
    "    'F1-Macro': [train_f1_macro, test_f1_macro, train_f1_macro - test_f1_macro],\n",
    "    'F1-Weighted': [train_f1_weighted, test_f1_weighted, train_f1_weighted - test_f1_weighted],\n",
    "    'Samples': [f'{len(y_train):,}', f'{len(y_test):,}', '-']\n",
    "})\n",
    "\n",
    "print(f\"\\nüìã Summary Table:\")\n",
    "print(results_summary.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BTQT)",
   "language": "python",
   "name": "btqt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
