{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 03: Adaptive Random Forest (ARF) – Giải pháp đề xuất\n",
        "\n",
        "Triển khai **ARF** (thư viện River) với **7 biến thể** drift detector để giảm Catastrophic Forgetting và thích nghi concept drift trên NSL-KDD, không lưu toàn bộ dữ liệu lịch sử. Đánh giá **theo phase** và báo cáo **AA, FM, BWT** (context §5–6).\n",
        "\n",
        "**Tham chiếu:** `exp_data/context/context_task_03.md`, `context_task_03_vie.md`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Lưu ý:** Nếu chưa cài River, chạy lệnh sau trong terminal hoặc trong một cell: `pip install river`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Import\n",
        "\n",
        "Dùng **River** cho ARF (online learning, drift detection tích hợp). Cấu hình đường dẫn và hằng số theo STRICT config từ context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config loaded. TARGET_CLASSES: ['Normal', 'DoS', 'Probe', 'R2L', 'U2R']\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup & Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- STRICT CONFIG (context_task_03) ---\n",
        "data_dir = Path(r'H:\\tdc_window\\Workspace\\Testspace\\ids\\exp_data')\n",
        "train_file = data_dir / 'KDDTrain+.txt'\n",
        "test_file = data_dir / 'KDDTest+.txt'\n",
        "\n",
        "categorical_cols = ['protocol_type', 'service', 'flag']\n",
        "TARGET_CLASSES = ['Normal', 'DoS', 'Probe', 'R2L', 'U2R']\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "standard_column_names = [\n",
        "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent',\n",
        "    'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login',\n",
        "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
        "    'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
        "    'attack_type', 'difficulty'\n",
        "]\n",
        "attack_categories = {\n",
        "    'Normal': 'normal',\n",
        "    'DoS': ['back', 'land', 'neptune', 'pod', 'smurf', 'teardrop', 'mailbomb', 'apache2', 'processtable', 'udpstorm'],\n",
        "    'Probe': ['ipsweep', 'nmap', 'portsweep', 'satan', 'mscan', 'saint'],\n",
        "    'R2L': ['ftp_write', 'guess_passwd', 'imap', 'multihop', 'phf', 'spy', 'warezclient', 'warezmaster', 'sendmail', 'named', 'snmpgetattack', 'snmpguess', 'xlock', 'xsnoop', 'worm'],\n",
        "    'U2R': ['buffer_overflow', 'loadmodule', 'perl', 'rootkit', 'httptunnel', 'ps', 'sqlattack', 'xterm']\n",
        "}\n",
        "print(\"Config loaded. TARGET_CLASSES:\", TARGET_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data\n",
        "\n",
        "Hàm load và map `attack_type` → `label` (5 lớp). Kiểm chứng: in `value_counts` và shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_df.shape: (125973, 44)\n",
            "test_df.shape: (22544, 44)\n",
            "\n",
            "Train label counts:\n",
            "label\n",
            "Normal    67343\n",
            "DoS       45927\n",
            "Probe     11656\n",
            "R2L         995\n",
            "U2R          52\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Data Loading\n",
        "def load_and_process_data(file_path, cols, mapping_dict, drop_difficulty=False):\n",
        "    df = pd.read_csv(file_path, names=cols)\n",
        "    df['attack_type'] = df['attack_type'].astype(str).str.strip().str.rstrip('.')\n",
        "    reversed_mapping = {}\n",
        "    for group, value in mapping_dict.items():\n",
        "        if isinstance(value, list):\n",
        "            for sub in value:\n",
        "                reversed_mapping[sub] = group\n",
        "        else:\n",
        "            reversed_mapping[value] = group\n",
        "    df['label'] = df['attack_type'].map(reversed_mapping).fillna('Unknown')\n",
        "    if drop_difficulty:\n",
        "        df = df.drop(columns=['difficulty'], errors='ignore')\n",
        "    return df\n",
        "\n",
        "train_df = load_and_process_data(train_file, standard_column_names, attack_categories)\n",
        "test_df = load_and_process_data(test_file, standard_column_names, attack_categories)\n",
        "print(\"train_df.shape:\", train_df.shape)\n",
        "print(\"test_df.shape:\", test_df.shape)\n",
        "print(\"\\nTrain label counts:\")\n",
        "print(train_df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering (Encoding)\n",
        "\n",
        "Cùng pipeline Task 2: loại bỏ `label`, `attack_type`, `difficulty`; OneHotEncoder cho categorical; remainder passthrough → 122 chiều."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_encoded.shape: (125973, 122)\n",
            "X_test_encoded.shape: (22544, 122)\n",
            "y_train (first 3): ['Normal', 'Normal', 'DoS']\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Encoding\n",
        "exclude_cols = ['label', 'attack_type', 'difficulty']\n",
        "X_train = train_df.drop(columns=exclude_cols)\n",
        "X_test = test_df.drop(columns=exclude_cols)\n",
        "y_train = train_df['label']\n",
        "y_test = test_df['label']\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('cat', encoder, categorical_cols)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "preprocessor.fit(X_train)\n",
        "X_train_encoded = preprocessor.transform(X_train)\n",
        "X_test_encoded = preprocessor.transform(X_test)\n",
        "\n",
        "print(\"X_train_encoded.shape:\", X_train_encoded.shape)\n",
        "print(\"X_test_encoded.shape:\", X_test_encoded.shape)\n",
        "print(\"y_train (first 3):\", y_train.head(3).tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Phase Splitting\n",
        "\n",
        "Phase 0 = Normal, DoS, Probe; Phase 1 = R2L only; Phase 2 = U2R only. Feed stream theo thứ tự 0 → 1 → 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phase 0: 124926 samples\n",
            "Phase 1 (R2L): 995 samples\n",
            "Phase 2 (U2R): 52 samples\n",
            "Test set: 22544 samples\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Phase split\n",
        "mask_phase0 = y_train.isin(['Normal', 'DoS', 'Probe'])\n",
        "mask_phase1 = (y_train == 'R2L')\n",
        "mask_phase2 = (y_train == 'U2R')\n",
        "\n",
        "X_phase0 = X_train_encoded[mask_phase0.values]\n",
        "y_phase0 = y_train[mask_phase0].values\n",
        "X_phase1 = X_train_encoded[mask_phase1.values]\n",
        "y_phase1 = y_train[mask_phase1].values\n",
        "X_phase2 = X_train_encoded[mask_phase2.values]\n",
        "y_phase2 = y_train[mask_phase2].values\n",
        "\n",
        "print(\"Phase 0:\", X_phase0.shape[0], \"samples\")\n",
        "print(\"Phase 1 (R2L):\", X_phase1.shape[0], \"samples\")\n",
        "print(\"Phase 2 (U2R):\", X_phase2.shape[0], \"samples\")\n",
        "print(\"Test set:\", X_test_encoded.shape[0], \"samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Helper: Convert sample to River dict\n",
        "\n",
        "River dùng `learn_one(x, y)` với `x` là dict. Chuyển mỗi hàng (122 số) thành dict `{\"f0\": v0, \"f1\": v1, ...}`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys (first 5): ['f0', 'f1', 'f2', 'f3', 'f4']\n",
            "Len: 122\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: River input format\n",
        "def row_to_dict(row):\n",
        "    return {f\"f{i}\": float(x) for i, x in enumerate(row)}\n",
        "\n",
        "# Quick check\n",
        "sample = row_to_dict(X_phase0[0])\n",
        "print(\"Keys (first 5):\", list(sample.keys())[:5])\n",
        "print(\"Len:\", len(sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Define ARF variants (River)\n",
        "\n",
        "**Tham số chung:** `n_models=100`, `grace_period=50`. Bảy biến thể theo drift detector:\n",
        "- 1) Base: không drift detector.\n",
        "- 2) ADWIN: adaptive windowing, thay đổi trung bình (gradual drift).\n",
        "- 3) KSWIN: Kolmogorov–Smirnov, thay đổi phân phối.\n",
        "- 4) Page-Hinkley: thay đổi đột ngột trung bình (abrupt).\n",
        "- 5) DDM: dựa trên tỷ lệ lỗi.\n",
        "- 6) HDDM_A: Hoeffding A-test (moving average).\n",
        "- 7) HDDM_W: Hoeffding W-test (weighted moving average)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variants: ['ARF_Base', 'ARF_ADWIN', 'ARF_KSWIN', 'ARF_PH', 'ARF_DDM', 'ARF_HDDM_A', 'ARF_HDDM_W']\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Build 7 ARF variants\n",
        "from river import forest\n",
        "from river import drift\n",
        "\n",
        "N_MODELS = 100\n",
        "GRACE_PERIOD = 50\n",
        "SEED = RANDOM_STATE\n",
        "\n",
        "def make_arf_base():\n",
        "    return forest.ARFClassifier(n_models=N_MODELS, grace_period=GRACE_PERIOD, seed=SEED, drift_detector=None, warning_detector=None)\n",
        "\n",
        "def make_arf_adwin():\n",
        "    d = drift.ADWIN(delta=0.001)\n",
        "    w = drift.ADWIN(delta=0.01)\n",
        "    return forest.ARFClassifier(n_models=N_MODELS, grace_period=GRACE_PERIOD, seed=SEED, drift_detector=d, warning_detector=w)\n",
        "\n",
        "def make_arf_kswin():\n",
        "    d = drift.KSWIN(alpha=0.005)\n",
        "    w = drift.KSWIN(alpha=0.01)\n",
        "    return forest.ARFClassifier(n_models=N_MODELS, grace_period=GRACE_PERIOD, seed=SEED, drift_detector=d, warning_detector=w)\n",
        "\n",
        "def make_arf_ph():\n",
        "    d = drift.PageHinkley()\n",
        "    return forest.ARFClassifier(n_models=N_MODELS, grace_period=GRACE_PERIOD, seed=SEED, drift_detector=d, warning_detector=None)\n",
        "\n",
        "def make_arf_ddm():\n",
        "    d = drift.DDM()\n",
        "    return forest.ARFClassifier(n_models=N_MODELS, grace_period=GRACE_PERIOD, seed=SEED, drift_detector=d, warning_detector=None)\n",
        "\n",
        "def make_arf_hddm_a():\n",
        "    d = drift.HDDM_A()\n",
        "    return forest.ARFClassifier(n_models=N_MODELS, grace_period=GRACE_PERIOD, seed=SEED, drift_detector=d, warning_detector=None)\n",
        "\n",
        "def make_arf_hddm_w():\n",
        "    d = drift.HDDM_W()\n",
        "    return forest.ARFClassifier(n_models=N_MODELS, grace_period=GRACE_PERIOD, seed=SEED, drift_detector=d, warning_detector=None)\n",
        "\n",
        "VARIANTS = [\n",
        "    ('ARF_Base', make_arf_base),\n",
        "    ('ARF_ADWIN', make_arf_adwin),\n",
        "    ('ARF_KSWIN', make_arf_kswin),\n",
        "    ('ARF_PH', make_arf_ph),\n",
        "    ('ARF_DDM', make_arf_ddm),\n",
        "    ('ARF_HDDM_A', make_arf_hddm_a),\n",
        "    ('ARF_HDDM_W', make_arf_hddm_w),\n",
        "]\n",
        "print(\"Variants:\", [v[0] for v in VARIANTS])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train stream & phase-wise evaluation (cho AA, FM, BWT)\n",
        "\n",
        "Hàm `train_arf_stream`: feed Phase 0 → 1 → 2 (không đánh giá giữa chừng). Hàm `train_arf_stream_with_eval`: feed từng phase rồi đánh giá ngay trên test set, trả về `(report_after_p0, report_after_p1, report_after_p2)` để tính AA, FM, BWT (context §5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_arf_stream and train_arf_stream_with_eval defined.\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Train stream (Phase 0 -> 1 -> 2) + phase-wise eval for AA/FM/BWT\n",
        "def train_arf_stream(model, X_phase0, y_phase0, X_phase1, y_phase1, X_phase2, y_phase2):\n",
        "    for i in range(len(X_phase0)):\n",
        "        model.learn_one(row_to_dict(X_phase0[i]), y_phase0[i])\n",
        "    for i in range(len(X_phase1)):\n",
        "        model.learn_one(row_to_dict(X_phase1[i]), y_phase1[i])\n",
        "    for i in range(len(X_phase2)):\n",
        "        model.learn_one(row_to_dict(X_phase2[i]), y_phase2[i])\n",
        "    return model\n",
        "\n",
        "def train_arf_stream_with_eval(model, X_phase0, y_phase0, X_phase1, y_phase1, X_phase2, y_phase2,\n",
        "                               X_test_encoded, y_test):\n",
        "    \"\"\"Train phase-by-phase; evaluate after each phase. Returns (report_p0, report_p1, report_p2).\"\"\"\n",
        "    for i in range(len(X_phase0)):\n",
        "        model.learn_one(row_to_dict(X_phase0[i]), y_phase0[i])\n",
        "    r0 = classification_report(y_test, predict_arf_batch(model, X_test_encoded),\n",
        "                               labels=TARGET_CLASSES, output_dict=True, zero_division=0)\n",
        "    for i in range(len(X_phase1)):\n",
        "        model.learn_one(row_to_dict(X_phase1[i]), y_phase1[i])\n",
        "    r1 = classification_report(y_test, predict_arf_batch(model, X_test_encoded),\n",
        "                               labels=TARGET_CLASSES, output_dict=True, zero_division=0)\n",
        "    for i in range(len(X_phase2)):\n",
        "        model.learn_one(row_to_dict(X_phase2[i]), y_phase2[i])\n",
        "    r2 = classification_report(y_test, predict_arf_batch(model, X_test_encoded),\n",
        "                               labels=TARGET_CLASSES, output_dict=True, zero_division=0)\n",
        "    return r0, r1, r2\n",
        "\n",
        "print(\"train_arf_stream and train_arf_stream_with_eval defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Predict on test set (batch)\n",
        "\n",
        "Duyệt từng mẫu test, gọi `predict_one(x)` và thu thập dự đoán để dùng với `classification_report`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict batch helper defined.\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Predict batch\n",
        "def predict_arf_batch(model, X_test_encoded):\n",
        "    preds = []\n",
        "    for i in range(len(X_test_encoded)):\n",
        "        x = row_to_dict(X_test_encoded[i])\n",
        "        p = model.predict_one(x)\n",
        "        preds.append(p if p is not None else TARGET_CLASSES[0])\n",
        "    return preds\n",
        "\n",
        "print(\"Predict batch helper defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Train & evaluate one variant (ARF_Base) – phase-wise\n",
        "\n",
        "Chạy thử ARF_Base với đánh giá sau từng phase (after_p0, after_p1, after_p2). In classification_report cuối để kiểm chứng."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After Phase 0 - macro F1: 0.4709696801393176\n",
            "After Phase 1 - macro F1: 0.04354494426436872\n",
            "After Phase 2 (final) - macro F1: 0.003517411185367569\n",
            "\n",
            "=== ARF_Base - classification_report (final) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.00      0.00      0.00      9711\n",
            "         DoS       0.00      0.00      0.00      7458\n",
            "       Probe       0.00      0.00      0.00      2421\n",
            "         R2L       0.00      0.00      0.00      2754\n",
            "         U2R       0.01      1.00      0.02       200\n",
            "\n",
            "    accuracy                           0.01     22544\n",
            "   macro avg       0.00      0.20      0.00     22544\n",
            "weighted avg       0.00      0.01      0.00     22544\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Train ARF_Base with phase-wise eval\n",
        "model_base = make_arf_base()\n",
        "rep0, rep1, rep2 = train_arf_stream_with_eval(\n",
        "    model_base, X_phase0, y_phase0, X_phase1, y_phase1, X_phase2, y_phase2,\n",
        "    X_test_encoded, y_test\n",
        ")\n",
        "print(\"After Phase 0 - macro F1:\", rep0.get(\"macro avg\", {}).get(\"f1-score\", 0))\n",
        "print(\"After Phase 1 - macro F1:\", rep1.get(\"macro avg\", {}).get(\"f1-score\", 0))\n",
        "print(\"After Phase 2 (final) - macro F1:\", rep2.get(\"macro avg\", {}).get(\"f1-score\", 0))\n",
        "print(\"\\n=== ARF_Base - classification_report (final) ===\")\n",
        "print(classification_report(y_test, predict_arf_batch(model_base, X_test_encoded),\n",
        "                            labels=TARGET_CLASSES, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Train & evaluate all 7 variants (phase-wise)\n",
        "\n",
        "Với mỗi biến thể: train theo phase và lưu `after_p0`, `after_p1`, `after_p2` để sau đó tính AA, FM, BWT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ARF_Base ...\n",
            "Training ARF_ADWIN ...\n",
            "Training ARF_KSWIN ...\n",
            "Training ARF_PH ...\n",
            "Training ARF_DDM ...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'river.drift' has no attribute 'DDM'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, make_model \u001b[38;5;129;01min\u001b[39;00m VARIANTS:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m\"\u001b[39m, name, \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     model = \u001b[43mmake_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     r0, r1, r2 = train_arf_stream_with_eval(\n\u001b[32m      7\u001b[39m         model, X_phase0, y_phase0, X_phase1, y_phase1, X_phase2, y_phase2,\n\u001b[32m      8\u001b[39m         X_test_encoded, y_test\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     10\u001b[39m     results[name] = {\u001b[33m\"\u001b[39m\u001b[33mafter_p0\u001b[39m\u001b[33m\"\u001b[39m: r0, \u001b[33m\"\u001b[39m\u001b[33mafter_p1\u001b[39m\u001b[33m\"\u001b[39m: r1, \u001b[33m\"\u001b[39m\u001b[33mafter_p2\u001b[39m\u001b[33m\"\u001b[39m: r2}\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mmake_arf_ddm\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_arf_ddm\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     d = \u001b[43mdrift\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDDM\u001b[49m()\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forest.ARFClassifier(n_models=N_MODELS, grace_period=GRACE_PERIOD, seed=SEED, drift_detector=d, warning_detector=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[31mAttributeError\u001b[39m: module 'river.drift' has no attribute 'DDM'"
          ]
        }
      ],
      "source": [
        "# Cell 10: Train all variants with phase-wise eval; store after_p0, after_p1, after_p2\n",
        "results = {}\n",
        "for name, make_model in VARIANTS:\n",
        "    print(\"Training\", name, \"...\")\n",
        "    model = make_model()\n",
        "    r0, r1, r2 = train_arf_stream_with_eval(\n",
        "        model, X_phase0, y_phase0, X_phase1, y_phase1, X_phase2, y_phase2,\n",
        "        X_test_encoded, y_test\n",
        "    )\n",
        "    results[name] = {\"after_p0\": r0, \"after_p1\": r1, \"after_p2\": r2}\n",
        "print(\"Done. Variants:\", list(results.keys()))\n",
        "print(\"Each result has keys:\", list(results[list(results.keys())[0]].keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary: F1 per class per variant\n",
        "\n",
        "In bảng F1 từng lớp cho từng biến thể (macro avg để so sánh nhanh)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: F1 summary table (final = after_p2)\n",
        "summary = []\n",
        "for name, reports in results.items():\n",
        "    report = reports[\"after_p2\"]\n",
        "    row = {\"variant\": name}\n",
        "    for cls in TARGET_CLASSES:\n",
        "        row[cls] = report.get(cls, {}).get(\"f1-score\", 0) or 0\n",
        "    row[\"macro_avg\"] = report.get(\"macro avg\", {}).get(\"f1-score\", 0) or 0\n",
        "    summary.append(row)\n",
        "summary_df = pd.DataFrame(summary)\n",
        "print(summary_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. AA, FM, BWT – định nghĩa và helper (context §5)\n",
        "\n",
        "- **AA (Average Accuracy):** Trung bình hiệu năng trên từng task tại thời điểm cuối (sau P2). Task 0 = Normal/DoS/Probe (macro F1), Task 1 = R2L, Task 2 = U2R.\n",
        "- **FM (Forgetting Measure):** F1 tốt nhất của task (ngay sau khi học xong task) trừ F1 của task tại cuối. FM > 0 = quên.\n",
        "- **BWT (Backward Transfer):** F1 của task tại cuối trừ F1 ngay sau khi học task đó. BWT < 0 = ảnh hưởng tiêu cực (quên). Tham khảo Task 2 cho logic FM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 12: Helpers for AA, FM, BWT\n",
        "CLASSES_TASK0 = [\"Normal\", \"DoS\", \"Probe\"]\n",
        "\n",
        "def f1_for_class(report, cls):\n",
        "    return report.get(cls, {}).get(\"f1-score\", 0) or 0\n",
        "\n",
        "def macro_f1_task0(report):\n",
        "    return np.mean([f1_for_class(report, c) for c in CLASSES_TASK0])\n",
        "\n",
        "def compute_aa_fm_bwt(reports):\n",
        "    \"\"\"reports = dict with keys after_p0, after_p1, after_p2 (each a classification_report dict).\"\"\"\n",
        "    r0, r1, r2 = reports[\"after_p0\"], reports[\"after_p1\"], reports[\"after_p2\"]\n",
        "    # AA: average over 3 tasks at final (after_p2)\n",
        "    aa = (macro_f1_task0(r2) + f1_for_class(r2, \"R2L\") + f1_for_class(r2, \"U2R\")) / 3.0\n",
        "    # FM: forgetting on task0 and task1 (task2 has no \"after\" to forget)\n",
        "    fm0 = macro_f1_task0(r0) - macro_f1_task0(r2)\n",
        "    fm1 = f1_for_class(r1, \"R2L\") - f1_for_class(r2, \"R2L\")\n",
        "    fm = (fm0 + fm1) / 2.0\n",
        "    # BWT: backward transfer (positive = good)\n",
        "    bwt0 = macro_f1_task0(r2) - macro_f1_task0(r0)\n",
        "    bwt1 = f1_for_class(r2, \"R2L\") - f1_for_class(r1, \"R2L\")\n",
        "    bwt = (bwt0 + bwt1) / 2.0\n",
        "    return aa, fm, bwt\n",
        "\n",
        "# Quick check on first variant\n",
        "name0 = list(results.keys())[0]\n",
        "aa0, fm0, bwt0 = compute_aa_fm_bwt(results[name0])\n",
        "print(f\"Example ({name0}): AA={aa0:.4f}, FM={fm0:.4f}, BWT={bwt0:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Bảng AA, FM, BWT theo từng biến thể\n",
        "\n",
        "In bảng so sánh AA, FM, BWT cho tất cả 7 biến thể (trước/sau khắc phục theo context)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 13: AA, FM, BWT table per variant\n",
        "metrics_rows = []\n",
        "for name in results:\n",
        "    aa, fm, bwt = compute_aa_fm_bwt(results[name])\n",
        "    metrics_rows.append({\"variant\": name, \"AA\": aa, \"FM\": fm, \"BWT\": bwt})\n",
        "metrics_df = pd.DataFrame(metrics_rows)\n",
        "print(\"=== AA, FM, BWT per variant (context §5) ===\")\n",
        "print(metrics_df.to_string(index=False))\n",
        "print(\"\\nFM > 0: forgetting; BWT < 0: negative backward transfer.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ARF_Base – Train streaming Phase0 -> Phase1 -> Phase2, evaluate sau mỗi phase\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "\n",
        "def train_arf_stream_with_eval_base(model,\n",
        "                                    X_phase0, y_phase0,\n",
        "                                    X_phase1, y_phase1,\n",
        "                                    X_phase2, y_phase2,\n",
        "                                    X_test_encoded, y_test,\n",
        "                                    log_interval=20000):\n",
        "    \"\"\"Train 1 mô hình ARF_Base theo thứ tự P0 -> P1 -> P2.\n",
        "\n",
        "    Sau mỗi phase, evaluate trên full test 5 lớp bằng classification_report.\n",
        "    Trả về (report_text_p0, report_text_p1, report_text_p2) để tiện tham chiếu.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Training ARF_Base with 3 phases (P0 -> P1 -> P2)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # ========== PHASE 0 ==========\n",
        "    print(f\"\\n[Phase 0] Training on {len(X_phase0):,} samples (Normal, DoS, Probe)...\")\n",
        "    start = time.time()\n",
        "    for i in range(len(X_phase0)):\n",
        "        model.learn_one(row_to_dict(X_phase0[i]), y_phase0[i])\n",
        "        if (i + 1) % log_interval == 0 or (i + 1) == len(X_phase0):\n",
        "            elapsed = time.time() - start\n",
        "            rate = (i + 1) / elapsed if elapsed > 0 else 0\n",
        "            print(f\"  [{i+1:6,}/{len(X_phase0):6,}]  Elapsed: {elapsed:6.1f}s  Rate: {rate:6.0f} samples/s\")\n",
        "    t0 = time.time() - start\n",
        "    print(f\"[Phase 0] Done in {t0:.1f}s\")\n",
        "\n",
        "    print(\"[Phase 0] Evaluating on full test set...\")\n",
        "    pred0 = predict_arf_batch(model, X_test_encoded)\n",
        "    rep0_text = classification_report(y_test, pred0, labels=TARGET_CLASSES, zero_division=0)\n",
        "    print(\"\\n=== ARF_Base - classification_report AFTER PHASE 0 ===\")\n",
        "    print(rep0_text)\n",
        "\n",
        "    # ========== PHASE 1 ==========\n",
        "    print(f\"\\n[Phase 1] Training on {len(X_phase1):,} samples (R2L only)...\")\n",
        "    start = time.time()\n",
        "    for i in range(len(X_phase1)):\n",
        "        model.learn_one(row_to_dict(X_phase1[i]), y_phase1[i])\n",
        "        if (i + 1) % log_interval == 0 or (i + 1) == len(X_phase1):\n",
        "            elapsed = time.time() - start\n",
        "            rate = (i + 1) / elapsed if elapsed > 0 else 0\n",
        "            print(f\"  [{i+1:6,}/{len(X_phase1):6,}]  Elapsed: {elapsed:6.1f}s  Rate: {rate:6.0f} samples/s\")\n",
        "    t1 = time.time() - start\n",
        "    print(f\"[Phase 1] Done in {t1:.1f}s\")\n",
        "\n",
        "    print(\"[Phase 1] Evaluating on full test set...\")\n",
        "    pred1 = predict_arf_batch(model, X_test_encoded)\n",
        "    rep1_text = classification_report(y_test, pred1, labels=TARGET_CLASSES, zero_division=0)\n",
        "    print(\"\\n=== ARF_Base - classification_report AFTER PHASE 1 ===\")\n",
        "    print(rep1_text)\n",
        "\n",
        "    # ========== PHASE 2 ==========\n",
        "    print(f\"\\n[Phase 2] Training on {len(X_phase2):,} samples (U2R only)...\")\n",
        "    start = time.time()\n",
        "    for i in range(len(X_phase2)):\n",
        "        model.learn_one(row_to_dict(X_phase2[i]), y_phase2[i])\n",
        "        if (i + 1) % max(1, log_interval // 10) == 0 or (i + 1) == len(X_phase2):\n",
        "            elapsed = time.time() - start\n",
        "            rate = (i + 1) / elapsed if elapsed > 0 else 0\n",
        "            print(f\"  [{i+1:4,}/{len(X_phase2):4,}]  Elapsed: {elapsed:6.2f}s  Rate: {rate:6.0f} samples/s\")\n",
        "    t2 = time.time() - start\n",
        "    print(f\"[Phase 2] Done in {t2:.2f}s\")\n",
        "\n",
        "    print(\"[Phase 2] Evaluating on full test set...\")\n",
        "    pred2 = predict_arf_batch(model, X_test_encoded)\n",
        "    rep2_text = classification_report(y_test, pred2, labels=TARGET_CLASSES, zero_division=0)\n",
        "    print(\"\\n=== ARF_Base - classification_report AFTER PHASE 2 ===\")\n",
        "    print(rep2_text)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ARF_Base training timeline:\")\n",
        "    print(f\"  Phase 0: {t0:.1f}s   Phase 1: {t1:.1f}s   Phase 2: {t2:.2f}s\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    return rep0_text, rep1_text, rep2_text\n",
        "\n",
        "\n",
        "# Khởi tạo ARF_Base và chạy huấn luyện 3 phase\n",
        "model_base_stream = make_arf_base()\n",
        "rep0_text, rep1_text, rep2_text = train_arf_stream_with_eval_base(\n",
        "    model_base_stream,\n",
        "    X_phase0, y_phase0,\n",
        "    X_phase1, y_phase1,\n",
        "    X_phase2, y_phase2,\n",
        "    X_test_encoded, y_test,\n",
        "    log_interval=20000,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "BTQT_conda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
